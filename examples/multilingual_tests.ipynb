{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22803a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from polyner import PolyNER\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe5611",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show polyner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f7aae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the processor\n",
    "processor = PolyNER()\n",
    "\n",
    "# Test text with multiple languages\n",
    "test_text = \"\"\"\n",
    "Apple Inc. is headquartered in Cupertino, California.\n",
    "Google tiene su sede en Mountain View.\n",
    "Amazon wurde von Jeff Bezos gegründet.\n",
    "Microsoft was founded by Bill Gates.\n",
    "La Tour Eiffel est située à Paris.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Testing multilingual processing with default model (Babelscape)...\")\n",
    "try:\n",
    "    # Process with default model (Babelscape)\n",
    "    result_default = processor.process_multi(test_text)\n",
    "    \n",
    "    # Display the results\n",
    "    print(\"\\nEntities detected (default model):\")\n",
    "    entities = result_default[result_default[\"entity_label\"].notna()]\n",
    "    print(entities[[\"token\", \"language\", \"entity_label\"]])\n",
    "    \n",
    "    # If we have confidence scores, show those too\n",
    "    if \"entity_score\" in entities.columns:\n",
    "        print(\"\\nWith confidence scores:\")\n",
    "        print(entities[[\"token\", \"language\", \"entity_label\", \"entity_score\"]])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error with default model: {e}\")\n",
    "    print(\"Note: To use Hugging Face models, install with: pip install transformers torch\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4e5537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with the XLM-RoBERTa model\n",
    "print(\"\\nTesting with XLM-RoBERTa model...\")\n",
    "try:\n",
    "    # Process with XLM-RoBERTa\n",
    "    result_xlm = processor.process_multi(test_text, model_name=\"xlm-roberta-base-finetuned-panx-all\")\n",
    "    \n",
    "    # Display the results\n",
    "    print(\"\\nEntities detected (XLM-RoBERTa):\")\n",
    "    entities_xlm = result_xlm[result_xlm[\"entity_label\"].notna()]\n",
    "    print(entities_xlm[[\"token\", \"language\", \"entity_label\"]])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error with XLM-RoBERTa model: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13a1698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with a spaCy model\n",
    "print(\"\\nTesting with spaCy model...\")\n",
    "try:\n",
    "    # Process with English spaCy model\n",
    "    result_spacy = processor.process_multi(test_text, model_name=\"en_core_web_sm\")\n",
    "    \n",
    "    # Display the results\n",
    "    print(\"\\nEntities detected (spaCy):\")\n",
    "    entities_spacy = result_spacy[result_spacy[\"entity_label\"].notna()]\n",
    "    print(entities_spacy[[\"token\", \"language\", \"entity_label\"]])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error with spaCy model: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc1571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTesting batch processing...\")\n",
    "test_texts = [\n",
    "    \"Apple Inc. is based in Cupertino.\",\n",
    "    \"Google tiene su sede en Mountain View.\",\n",
    "    \"Amazon wurde von Jeff Bezos gegründet.\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Process batch with default model\n",
    "    batch_results = processor.process_batch_multi(test_texts)\n",
    "    \n",
    "    # Display the results for each text\n",
    "    for i, result in enumerate(batch_results):\n",
    "        print(f\"\\nText {i+1} entities:\")\n",
    "        text_entities = result[result[\"entity_label\"].notna()]\n",
    "        print(text_entities[[\"token\", \"language\", \"entity_label\"]])\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error with batch processing: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polyner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
